{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22f107a4d9074fecad6dbb72bb7a6c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_243c5a908c86481eab24d9282b959402",
              "IPY_MODEL_17e0ebaa34614bcaab8cb3bf83917bad",
              "IPY_MODEL_61f8b915085e48e99b9876812a242c01"
            ],
            "layout": "IPY_MODEL_9074643cd868470da95fce9fe2b2e0fc"
          }
        },
        "243c5a908c86481eab24d9282b959402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c04b26602aa45e1b5e04f1948559c06",
            "placeholder": "​",
            "style": "IPY_MODEL_4e85131430124eb98d6fff07a79a3c97",
            "value": ""
          }
        },
        "17e0ebaa34614bcaab8cb3bf83917bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec3f4639b3541019e040c1e0e2de782",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e37a0c7d061e46b5925de7c1c0057674",
            "value": 170498071
          }
        },
        "61f8b915085e48e99b9876812a242c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7487035649bc44f38d98986e133d2365",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe3eca4cb8b4e8994ef651b53bb2ca0",
            "value": " 170499072/? [00:02&lt;00:00, 81977279.78it/s]"
          }
        },
        "9074643cd868470da95fce9fe2b2e0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c04b26602aa45e1b5e04f1948559c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e85131430124eb98d6fff07a79a3c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec3f4639b3541019e040c1e0e2de782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37a0c7d061e46b5925de7c1c0057674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7487035649bc44f38d98986e133d2365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe3eca4cb8b4e8994ef651b53bb2ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr[\"simulation\"]==0.18.0 torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om9qQyOM66uG",
        "outputId": "bcfb73af-39d8-48db-9e43-79d94a64f4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flwr[simulation]==0.18.0\n",
            "  Downloading flwr-0.18.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Collecting grpcio<=1.43.0,>=1.27.2\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 40.6 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<2.0.0,>=1.4.0\n",
            "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]==0.18.0) (3.17.3)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]==0.18.0) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]==0.18.0) (1.21.6)\n",
            "Collecting ray[default]<2.0.0,>=1.9.2\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 152 kB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr[simulation]==0.18.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.27.2->flwr[simulation]==0.18.0) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0.0,>=1.4.0->flwr[simulation]==0.18.0) (3.8.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (21.4.0)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (3.7.1)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (1.0.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (4.3.3)\n",
            "Collecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (5.2.1)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting aiohttp>=3.7\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 59.9 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 47.3 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 270 kB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 76.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py3>=7.352.0\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (5.4.8)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (0.2.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.7->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (2.10)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (0.18.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (1.31.6)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (1.56.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (1.35.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (2022.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (4.2.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]<2.0.0,>=1.9.2->flwr[simulation]==0.18.0) (3.0.4)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 47.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gpustat, nvidia-ml-py3\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=802fb1f3aa695ab174e47ed1f9b188fed37663ee9c793554de7e3a7ba3d69014\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19190 sha256=e55b9d5c118f0638a979b73e476c8381cdbd13aa35cfde5b43f12a2382af79ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\n",
            "Successfully built gpustat nvidia-ml-py3\n",
            "Installing collected packages: multidict, frozenlist, yarl, platformdirs, importlib-metadata, distlib, asynctest, async-timeout, aiosignal, virtualenv, opencensus-context, nvidia-ml-py3, grpcio, blessed, aiohttp, ray, py-spy, prometheus-client, opencensus, gpustat, colorful, aiohttp-cors, flwr\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.14.1\n",
            "    Uninstalling prometheus-client-0.14.1:\n",
            "      Successfully uninstalled prometheus-client-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-cors-0.7.0 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 blessed-1.19.1 colorful-0.5.4 distlib-0.3.4 flwr-0.18.0 frozenlist-1.3.0 gpustat-1.0.0b1 grpcio-1.43.0 importlib-metadata-1.7.0 multidict-6.0.2 nvidia-ml-py3-7.352.0 opencensus-0.9.0 opencensus-context-0.1.2 platformdirs-2.5.2 prometheus-client-0.13.1 py-spy-0.3.12 ray-1.13.0 virtualenv-20.14.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtBsrYPK5yO0",
        "outputId": "9c734723-4e6d-42e2-824b-7b144f7865e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the CIFAR-10 training and test set, partition them into ten smaller datasets"
      ],
      "metadata": {
        "id": "8NGn5oAPxCv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "22f107a4d9074fecad6dbb72bb7a6c34",
            "243c5a908c86481eab24d9282b959402",
            "17e0ebaa34614bcaab8cb3bf83917bad",
            "61f8b915085e48e99b9876812a242c01",
            "9074643cd868470da95fce9fe2b2e0fc",
            "8c04b26602aa45e1b5e04f1948559c06",
            "4e85131430124eb98d6fff07a79a3c97",
            "3ec3f4639b3541019e040c1e0e2de782",
            "e37a0c7d061e46b5925de7c1c0057674",
            "7487035649bc44f38d98986e133d2365",
            "6fe3eca4cb8b4e8994ef651b53bb2ca0"
          ]
        },
        "id": "2i3VM4rO51aq",
        "outputId": "fd747f7d-1c78-4dd0-8669-5619881e58ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22f107a4d9074fecad6dbb72bb7a6c34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training/evaluation"
      ],
      "metadata": {
        "id": "rPkNEMmzxJTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(testloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "lVfA9Ioc5-c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Flower client"
      ],
      "metadata": {
        "id": "gMqo1QPZxXqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "RJ3bOxun6GUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Server-side parameter initialization"
      ],
      "metadata": {
        "id": "gP7KeFWBx5uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flower, by default, initializes the global model by asking one random client for the initial parameters."
      ],
      "metadata": {
        "id": "DXAILPSKx6e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "params = get_parameters(Net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(params),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0qtUUl6Kgs",
        "outputId": "f7d124f7-94aa-4c33-d2fd-6e5e055f00e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-06-23 14:17:06,934 | app.py:147 | Ray initialized with resources: {'CPU': 2.0, 'memory': 7887246951.0, 'node:172.28.0.2': 1.0, 'object_store_memory': 3943623475.0}\n",
            "INFO flower 2022-06-23 14:17:06,944 | app.py:156 | Starting Flower simulation running: {'num_rounds': 3}\n",
            "INFO flower 2022-06-23 14:17:06,948 | server.py:128 | Initializing global parameters\n",
            "INFO flower 2022-06-23 14:17:06,949 | server.py:323 | Using initial parameters provided by strategy\n",
            "INFO flower 2022-06-23 14:17:06,952 | server.py:130 | Evaluating initial parameters\n",
            "INFO flower 2022-06-23 14:17:06,957 | server.py:143 | FL starting\n",
            "DEBUG flower 2022-06-23 14:17:06,959 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m Epoch 1: train loss 0.028955044224858284, accuracy 0.23066666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m Epoch 1: train loss 0.02939736284315586, accuracy 0.22355555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m [Client 2] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:17:21,447 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:17:21,466 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m Epoch 1: train loss 0.029448186978697777, accuracy 0.216\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=274)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=273)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:17:26,740 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:17:26,742 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=273)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m Epoch 1: train loss 0.025723392143845558, accuracy 0.3228888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m Epoch 1: train loss 0.02640993893146515, accuracy 0.30577777777777776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:17:38,687 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:17:38,705 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m Epoch 1: train loss 0.02627427689731121, accuracy 0.30622222222222223\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=274)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=273)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:17:43,643 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:17:43,645 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=274)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m Epoch 1: train loss 0.024465057998895645, accuracy 0.36133333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=274)\u001b[0m Epoch 1: train loss 0.02450534515082836, accuracy 0.3562222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:17:54,878 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:17:54,894 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=273)\u001b[0m Epoch 1: train loss 0.024053696542978287, accuracy 0.38555555555555554\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=274)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=273)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:00,050 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:18:00,052 | server.py:182 | FL finished in 53.09333215900003\n",
            "INFO flower 2022-06-23 14:18:00,058 | app.py:149 | app_fit: losses_distributed [(1, 0.06236810111999511), (2, 0.05608209506670634), (3, 0.05276714571317037)]\n",
            "INFO flower 2022-06-23 14:18:00,061 | app.py:150 | app_fit: metrics_distributed {}\n",
            "INFO flower 2022-06-23 14:18:00,063 | app.py:151 | app_fit: losses_centralized []\n",
            "INFO flower 2022-06-23 14:18:00,065 | app.py:152 | app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=274)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.06236810111999511\n",
              "\tround 2: 0.05608209506670634\n",
              "\tround 3: 0.05276714571317037"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting with a customized strategy"
      ],
      "metadata": {
        "id": "G6He0W7vyJXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The strategy encapsulates the federated learning approach/algorithm, for example, FedAvg or FedAdagrad.So Now try with both strategy"
      ],
      "metadata": {
        "id": "B6a8PXpKyKRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAdam strategy\n",
        "strategy=fl.server.strategy.FedAdagrad(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_XagtZD6N--",
        "outputId": "a2da21ab-bcc5-44e9-e02c-baf6ffe0e056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-06-23 14:18:06,993 | app.py:147 | Ray initialized with resources: {'node:172.28.0.2': 1.0, 'memory': 7890041243.0, 'CPU': 2.0, 'object_store_memory': 3945020620.0}\n",
            "INFO flower 2022-06-23 14:18:06,997 | app.py:156 | Starting Flower simulation running: {'num_rounds': 3}\n",
            "INFO flower 2022-06-23 14:18:07,001 | server.py:128 | Initializing global parameters\n",
            "INFO flower 2022-06-23 14:18:07,004 | server.py:323 | Using initial parameters provided by strategy\n",
            "INFO flower 2022-06-23 14:18:07,007 | server.py:130 | Evaluating initial parameters\n",
            "INFO flower 2022-06-23 14:18:07,010 | server.py:143 | FL starting\n",
            "DEBUG flower 2022-06-23 14:18:07,014 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m Epoch 1: train loss 0.028966635465621948, accuracy 0.234\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m Epoch 1: train loss 0.029385993257164955, accuracy 0.228\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m [Client 3] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:19,624 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:18:19,649 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m Epoch 1: train loss 0.029441609978675842, accuracy 0.21733333333333332\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=534)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=535)\u001b[0m [Client 7] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:24,792 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:18:24,794 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=534)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m Epoch 1: train loss 0.22643797099590302, accuracy 0.27066666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m Epoch 1: train loss 0.23240859806537628, accuracy 0.2788888888888889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:35,893 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:18:35,911 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m Epoch 1: train loss 0.2634830176830292, accuracy 0.2551111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=535)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=534)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=535)\u001b[0m [Client 8] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:40,819 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:18:40,820 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m Epoch 1: train loss 0.03842727467417717, accuracy 0.14177777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=534)\u001b[0m Epoch 1: train loss 0.03837426006793976, accuracy 0.1302222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m [Client 5] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:51,652 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:18:51,671 | server.py:215 | evaluate_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=535)\u001b[0m Epoch 1: train loss 0.038299087435007095, accuracy 0.12866666666666668\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=535)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=534)\u001b[0m [Client 6] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:18:56,700 | server.py:227 | evaluate_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:18:56,703 | server.py:182 | FL finished in 49.68908798199999\n",
            "INFO flower 2022-06-23 14:18:56,710 | app.py:149 | app_fit: losses_distributed [(1, 3.3032486699422203), (2, 0.35022931861877443), (3, 0.09931291103363038)]\n",
            "INFO flower 2022-06-23 14:18:56,712 | app.py:150 | app_fit: metrics_distributed {}\n",
            "INFO flower 2022-06-23 14:18:56,718 | app.py:151 | app_fit: losses_centralized []\n",
            "INFO flower 2022-06-23 14:18:56,720 | app.py:152 | app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=535)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 3.3032486699422203\n",
              "\tround 2: 0.35022931861877443\n",
              "\tround 3: 0.09931291103363038"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The `evaluate` function will be by Flower called after every round\n",
        "def evaluate(\n",
        "    weights: fl.common.Weights,\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net()\n",
        "    valloader = valloaders[0]\n",
        "    set_parameters(net, weights)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "10iIFMu46Vp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        "    eval_fn=evaluate,  # Pass the evaluation function\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNQg8NTa6WW1",
        "outputId": "9298d648-cc5e-4faa-8289-2e0f0929f9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-06-23 14:19:02,939 | app.py:147 | Ray initialized with resources: {'object_store_memory': 3945019392.0, 'memory': 7890038784.0, 'CPU': 2.0, 'node:172.28.0.2': 1.0}\n",
            "INFO flower 2022-06-23 14:19:02,943 | app.py:156 | Starting Flower simulation running: {'num_rounds': 3}\n",
            "INFO flower 2022-06-23 14:19:02,948 | server.py:128 | Initializing global parameters\n",
            "INFO flower 2022-06-23 14:19:02,950 | server.py:323 | Using initial parameters provided by strategy\n",
            "INFO flower 2022-06-23 14:19:02,955 | server.py:130 | Evaluating initial parameters\n",
            "INFO flower 2022-06-23 14:19:03,267 | server.py:137 | initial parameters (loss, other metrics): 0.07375648212432862, {'accuracy': 0.092}\n",
            "INFO flower 2022-06-23 14:19:03,274 | server.py:143 | FL starting\n",
            "DEBUG flower 2022-06-23 14:19:03,280 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07375648212432862 / accuracy 0.092\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.029604105278849602, accuracy 0.20266666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m Epoch 1: train loss 0.029293237254023552, accuracy 0.21555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:19:15,889 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:19:16,098 | server.py:164 | fit progress: (1, 0.06275381827354432, {'accuracy': 0.304}, 12.817744654999984)\n",
            "INFO flower 2022-06-23 14:19:16,100 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "DEBUG flower 2022-06-23 14:19:16,117 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.02880917303264141, accuracy 0.22866666666666666\n",
            "Server-side evaluation loss 0.06275381827354432 / accuracy 0.304\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.025630448013544083, accuracy 0.3422222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m Epoch 1: train loss 0.02544352412223816, accuracy 0.3437777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:19:27,425 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:19:27,628 | server.py:164 | fit progress: (2, 0.05512853932380676, {'accuracy': 0.362}, 24.347483306999976)\n",
            "INFO flower 2022-06-23 14:19:27,629 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "DEBUG flower 2022-06-23 14:19:27,636 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.025804979726672173, accuracy 0.32911111111111113\n",
            "Server-side evaluation loss 0.05512853932380676 / accuracy 0.362\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.023649688810110092, accuracy 0.38555555555555554\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=777)\u001b[0m Epoch 1: train loss 0.0242004431784153, accuracy 0.37577777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:19:38,850 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:19:39,061 | server.py:164 | fit progress: (3, 0.053611843585968016, {'accuracy': 0.396}, 35.78112193399997)\n",
            "INFO flower 2022-06-23 14:19:39,064 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "INFO flower 2022-06-23 14:19:39,068 | server.py:182 | FL finished in 35.78733605099998\n",
            "INFO flower 2022-06-23 14:19:39,071 | app.py:149 | app_fit: losses_distributed []\n",
            "INFO flower 2022-06-23 14:19:39,074 | app.py:150 | app_fit: metrics_distributed {}\n",
            "INFO flower 2022-06-23 14:19:39,075 | app.py:151 | app_fit: losses_centralized [(0, 0.07375648212432862), (1, 0.06275381827354432), (2, 0.05512853932380676), (3, 0.053611843585968016)]\n",
            "INFO flower 2022-06-23 14:19:39,077 | app.py:152 | app_fit: metrics_centralized {'accuracy': [(0, 0.092), (1, 0.304), (2, 0.362), (3, 0.396)]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=778)\u001b[0m Epoch 1: train loss 0.02394915744662285, accuracy 0.38422222222222224\n",
            "Server-side evaluation loss 0.053611843585968016 / accuracy 0.396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 0.07375648212432862\n",
              "\tround 1: 0.06275381827354432\n",
              "\tround 2: 0.05512853932380676\n",
              "\tround 3: 0.053611843585968016\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.092), (1, 0.304), (2, 0.362), (3, 0.396)]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        current_round = config[\"current_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "IMgF8Cnv6ZQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_config(rnd: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "    \n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"current_round\": rnd,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if rnd < 2 else 2,  # \n",
        "    }\n",
        "    return config"
      ],
      "metadata": {
        "id": "RQduPqXx6dOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        "    eval_fn=evaluate,\n",
        "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XD8uT7L6j2a",
        "outputId": "a5076db3-8dd8-4be6-d881-1b5f418066b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-06-23 14:19:45,439 | app.py:147 | Ray initialized with resources: {'memory': 7889736500.0, 'object_store_memory': 3944868249.0, 'CPU': 2.0, 'node:172.28.0.2': 1.0}\n",
            "INFO flower 2022-06-23 14:19:45,447 | app.py:156 | Starting Flower simulation running: {'num_rounds': 3}\n",
            "INFO flower 2022-06-23 14:19:45,451 | server.py:128 | Initializing global parameters\n",
            "INFO flower 2022-06-23 14:19:45,455 | server.py:323 | Using initial parameters provided by strategy\n",
            "INFO flower 2022-06-23 14:19:45,460 | server.py:130 | Evaluating initial parameters\n",
            "INFO flower 2022-06-23 14:19:45,709 | server.py:137 | initial parameters (loss, other metrics): 0.0738621392250061, {'accuracy': 0.084}\n",
            "INFO flower 2022-06-23 14:19:45,715 | server.py:143 | FL starting\n",
            "DEBUG flower 2022-06-23 14:19:45,716 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.0738621392250061 / accuracy 0.084\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m [Client 3, round 1] fit, config: {'current_round': 1, 'local_epochs': 1}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m [Client 1, round 1] fit, config: {'current_round': 1, 'local_epochs': 1}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 1: train loss 0.029214102774858475, accuracy 0.2262222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 1: train loss 0.02891010046005249, accuracy 0.24244444444444443\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m [Client 2, round 1] fit, config: {'current_round': 1, 'local_epochs': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:19:58,243 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:19:58,444 | server.py:164 | fit progress: (1, 0.06240503478050232, {'accuracy': 0.302}, 12.72770052200002)\n",
            "INFO flower 2022-06-23 14:19:58,446 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "DEBUG flower 2022-06-23 14:19:58,451 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 1: train loss 0.029160788282752037, accuracy 0.2157777777777778\n",
            "Server-side evaluation loss 0.06240503478050232 / accuracy 0.302\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m [Client 4, round 2] fit, config: {'current_round': 2, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m [Client 6, round 2] fit, config: {'current_round': 2, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 1: train loss 0.025801805779337883, accuracy 0.32622222222222225\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 1: train loss 0.025917483493685722, accuracy 0.31444444444444447\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 2: train loss 0.023479612544178963, accuracy 0.38622222222222224\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 2: train loss 0.02384360134601593, accuracy 0.382\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m [Client 0, round 2] fit, config: {'current_round': 2, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 1: train loss 0.025814959779381752, accuracy 0.32822222222222225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:20:16,261 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:20:16,462 | server.py:164 | fit progress: (2, 0.051755956411361694, {'accuracy': 0.398}, 30.746024709999972)\n",
            "INFO flower 2022-06-23 14:20:16,464 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "DEBUG flower 2022-06-23 14:20:16,468 | server.py:269 | fit_round: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 2: train loss 0.023618806153535843, accuracy 0.38866666666666666\n",
            "Server-side evaluation loss 0.051755956411361694 / accuracy 0.398\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m [Client 8, round 3] fit, config: {'current_round': 3, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m [Client 0, round 3] fit, config: {'current_round': 3, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 1: train loss 0.022692853584885597, accuracy 0.406\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 1: train loss 0.022672632709145546, accuracy 0.4131111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 2: train loss 0.021439742296934128, accuracy 0.44355555555555554\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m [Client 4, round 3] fit, config: {'current_round': 3, 'local_epochs': 2}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1020)\u001b[0m Epoch 2: train loss 0.021295150741934776, accuracy 0.44955555555555554\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 1: train loss 0.022391710430383682, accuracy 0.42155555555555557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:20:34,323 | server.py:281 | fit_round received 3 results and 0 failures\n",
            "INFO flower 2022-06-23 14:20:34,522 | server.py:164 | fit progress: (3, 0.04895351314544678, {'accuracy': 0.444}, 48.80559737599998)\n",
            "INFO flower 2022-06-23 14:20:34,528 | server.py:209 | evaluate_round: no clients selected, cancel\n",
            "INFO flower 2022-06-23 14:20:34,529 | server.py:182 | FL finished in 48.812695958999996\n",
            "INFO flower 2022-06-23 14:20:34,536 | app.py:149 | app_fit: losses_distributed []\n",
            "INFO flower 2022-06-23 14:20:34,539 | app.py:150 | app_fit: metrics_distributed {}\n",
            "INFO flower 2022-06-23 14:20:34,540 | app.py:151 | app_fit: losses_centralized [(0, 0.0738621392250061), (1, 0.06240503478050232), (2, 0.051755956411361694), (3, 0.04895351314544678)]\n",
            "INFO flower 2022-06-23 14:20:34,542 | app.py:152 | app_fit: metrics_centralized {'accuracy': [(0, 0.084), (1, 0.302), (2, 0.398), (3, 0.444)]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1021)\u001b[0m Epoch 2: train loss 0.021189486607909203, accuracy 0.45711111111111113\n",
            "Server-side evaluation loss 0.04895351314544678 / accuracy 0.444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, centralized):\n",
              "\tround 0: 0.0738621392250061\n",
              "\tround 1: 0.06240503478050232\n",
              "\tround 2: 0.051755956411361694\n",
              "\tround 3: 0.04895351314544678\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.084), (1, 0.302), (2, 0.398), (3, 0.444)]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling federated learning"
      ],
      "metadata": {
        "id": "DHy4jzGvy0WO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can use Flower to experiment with a large number of clients."
      ],
      "metadata": {
        "id": "tx7jmFAMy1TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 1000\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmZXmnHV6oP5",
        "outputId": "e8418788-44a4-44f8-a043-198695b6b6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_config(rnd: int):\n",
        "    config = {\n",
        "        \"current_round\": rnd,\n",
        "        \"local_epochs\": 3,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.025,  # Train on 25 clients (each round)\n",
        "    fraction_eval=0.05,  # Evaluate on 50 clients (each round)\n",
        "    min_fit_clients=20,\n",
        "    min_eval_clients=40,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        "    on_fit_config_fn=fit_config,\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y69faG5u6r5r",
        "outputId": "75fa6702-c612-463f-b3c3-b09ea8637bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flower 2022-06-23 14:20:43,106 | app.py:147 | Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3944944435.0, 'node:172.28.0.2': 1.0, 'memory': 7889888871.0}\n",
            "INFO flower 2022-06-23 14:20:43,110 | app.py:156 | Starting Flower simulation running: {'num_rounds': 3}\n",
            "INFO flower 2022-06-23 14:20:43,135 | server.py:128 | Initializing global parameters\n",
            "INFO flower 2022-06-23 14:20:43,143 | server.py:323 | Using initial parameters provided by strategy\n",
            "INFO flower 2022-06-23 14:20:43,152 | server.py:130 | Evaluating initial parameters\n",
            "INFO flower 2022-06-23 14:20:43,155 | server.py:143 | FL starting\n",
            "DEBUG flower 2022-06-23 14:20:43,162 | server.py:269 | fit_round: strategy sampled 25 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 184, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 956, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004614427452906966, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.000457173737231642, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046183165977708995, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004552064056042582, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000456655106972903, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00045476044761016965, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 242, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004611019103322178, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045716247404925525, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004552155442070216, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 420, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046209708671085536, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00045678234891965985, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004532668099272996, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 496, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046216879854910076, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004596232029143721, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004544462717603892, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 79, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004607031005434692, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004551461315713823, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004530668375082314, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 319, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046017192653380334, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004536078486125916, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004511038423515856, accuracy 0.28888888888888886\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 912, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.000459794100606814, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045646363287232816, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00045487607712857425, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 517, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046219248906709254, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045595463598147035, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004540103836916387, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 250, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046294869389384985, accuracy 0.044444444444444446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004578543594107032, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004567948344629258, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 527, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 561, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046073016710579395, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004593917983584106, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004539801157079637, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004553313192445785, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004482189251575619, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00044492119923233986, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 913, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046380158164538443, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 758, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045775732723996043, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004593422927428037, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00045517596299760044, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004548109427560121, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00044816170702688396, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 845, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 978, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004579189408104867, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.000458588358014822, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004544021503534168, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004525691911112517, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000450227438705042, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004466715909074992, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 928, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045826463610865176, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004530319129116833, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00044405393418855965, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 811, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004571472236420959, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004544746479950845, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004443452344276011, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 105, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046414919779635966, accuracy 0.044444444444444446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045770438737235963, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000452829641290009, accuracy 0.24444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 3359 MiB, 36 objects, write throughput 193 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 475, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004597997176460922, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 394, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004569399752654135, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046248387661762536, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000449405109975487, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004565802519209683, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.000454375782283023, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 468, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 225, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004574041231535375, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004616868100129068, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004526977427303791, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00044385463115759194, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045702734496444464, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00045486842282116413, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 681, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046046104398556054, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 722, round 1] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00045616397983394563, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046101093175821006, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004506490658968687, accuracy 0.15555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:21:42,169 | server.py:281 | fit_round received 25 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004564874689094722, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004516459011938423, accuracy 0.17777777777777778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:21:42,584 | server.py:215 | evaluate_round: strategy sampled 50 clients (out of 1000)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4773 MiB, 53 objects, write throughput 208 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 609] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 262] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 499] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 132] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 933] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 910] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 784] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 276] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 84] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 148] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 333] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 931] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 122] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 726] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 178] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 602] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 743] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 705] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 101] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 968] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 690] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 488] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 211] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 207] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 883] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 127] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 584] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 920] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 460] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 432] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 884] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 135] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 713] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 57] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 440] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 354] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 16] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 545] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 212] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 8663 MiB, 94 objects, write throughput 225 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 13] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 202] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 344] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 192] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 105] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 474] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 416] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 645] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 908] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:23:17,956 | server.py:227 | evaluate_round received 50 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:23:17,966 | server.py:269 | fit_round: strategy sampled 25 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 158] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 587, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045760220382362604, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004539361107163131, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004358128644526005, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 791, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004526679986156523, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.000439821946201846, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004345017368905246, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 336, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045989771024324, accuracy 0.044444444444444446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004569638695102185, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 920, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004467166436370462, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045618435251526535, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004513325111474842, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043287468724884093, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 58, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.000462730647996068, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004508041311055422, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043320341501384974, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 202, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004558594082482159, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004471268621273339, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004302014713175595, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 665, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004574329359456897, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004506200202740729, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043932246626354754, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 341, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004597496590577066, accuracy 0.044444444444444446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004543292161542922, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000446683174232021, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 954, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045810217852704227, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004547900171019137, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00044767025974579155, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 237, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 27, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004617250815499574, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004584173148032278, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004543427494354546, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004488594422582537, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043462147004902363, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00045023049460723996, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 771, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004588436568155885, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00045390668674372137, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004455360467545688, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 612, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 292, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045832153409719467, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004583334375638515, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.000455433561000973, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004477062320802361, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00044836796587333083, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.000438899704022333, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 938, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 540, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046134291915223, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046241647214628756, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.000454526802059263, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00044870070996694267, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045708188554272056, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004503982490859926, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 510, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004615924844983965, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 459, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045525789028033614, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004596879007294774, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004515135660767555, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00044831709237769246, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004426314262673259, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 350, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004595247155521065, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004538373905234039, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004406162188388407, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 953, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 874, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045595693518407643, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045950032654218376, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004469610285013914, accuracy 0.28888888888888886\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00045496548409573734, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004413337155710906, accuracy 0.28888888888888886\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004465759266167879, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 618, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 947, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046120985643938184, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00046042384929023683, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045180460438132286, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004510064609348774, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004439663025550544, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004455388989299536, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 781, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004558610380627215, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 871, round 2] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004421779594849795, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045611386303789914, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004363909247331321, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00044874456943944097, accuracy 0.2222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:24:13,404 | server.py:281 | fit_round received 25 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004376948345452547, accuracy 0.2222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:24:13,861 | server.py:215 | evaluate_round: strategy sampled 50 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 183] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 258] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 636] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 653] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 597] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 820] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 651] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 516] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 413] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 32] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 753] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 232] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 635] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 353] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 815] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 767] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 714] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 148] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 963] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 671] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 821] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 214] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 827] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 285] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 847] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 584] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 977] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 132] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 262] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 272] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 586] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 457] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 235] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 771] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 451] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 681] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 793] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 388] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 505] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 429] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 407] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 347] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 802] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 16443 MiB, 183 objects, write throughput 237 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 596] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 601] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 822] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 957] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 665] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 527] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:25:48,110 | server.py:227 | evaluate_round received 50 results and 0 failures\n",
            "DEBUG flower 2022-06-23 14:25:48,118 | server.py:269 | fit_round: strategy sampled 25 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 268] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 974, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004497231566347182, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00042461452540010214, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 917, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004415915464051068, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045321189099922776, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00042899366235360503, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043383537558838725, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 727, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004502646334003657, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 781, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004173885390628129, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00045197276631370187, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00040818413253873587, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00043338260729797184, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004134471819270402, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 498, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 435, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00044827061356045306, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004475190071389079, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004324585315771401, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00042993048555217683, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004222142160870135, accuracy 0.3333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00042675904114730656, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 807, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004465926031116396, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004303674795664847, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.000419287767726928, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 396, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004544654511846602, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00044155187788419425, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043553338036872447, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 866, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045097016845829785, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004479723866097629, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004301714070606977, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 449, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004605559806805104, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00044524759869091213, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004358457517810166, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 624, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046364060835912824, accuracy 0.044444444444444446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 103, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045459490502253175, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004593706107698381, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004531269078142941, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00045071248314343393, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00044595226063393056, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 230, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 603, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045700196642428637, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00046343388385139406, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045411926112137735, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004379712918307632, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004235667292959988, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00044124198029749095, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 343, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004503033705987036, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 878, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00043265119893476367, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004575661732815206, accuracy 0.06666666666666667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00041597566450946033, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004462920769583434, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00043247375288046896, accuracy 0.15555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 366, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 95, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.00045866280561313033, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004566654097288847, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00044659728882834315, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00044054898899048567, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004382240294944495, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00044213022920303047, accuracy 0.2222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 838, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004594816127792001, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004477416514419019, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00043506885413080454, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 784, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004571643366944045, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004449612752068788, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0004259739944245666, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 585, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004547960706986487, accuracy 0.08888888888888889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00045003253035247326, accuracy 0.28888888888888886\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 887, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.0004312498203944415, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.000457856833236292, accuracy 0.1111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.00044307185453362763, accuracy 0.26666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 440, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.00043266519787721336, accuracy 0.3111111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.00044580077519640326, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.0004323676985222846, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00041377314482815564, accuracy 0.35555555555555557\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m [Client 71, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 1: train loss 0.0004375403805170208, accuracy 0.24444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 2: train loss 0.0004143312107771635, accuracy 0.2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1261)\u001b[0m Epoch 3: train loss 0.0003983166825491935, accuracy 0.24444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:26:44,430 | server.py:281 | fit_round received 25 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m [Client 300, round 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 1: train loss 0.0004621656844392419, accuracy 0.13333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 2: train loss 0.00044814328430220485, accuracy 0.17777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1262)\u001b[0m Epoch 3: train loss 0.00044808321399614215, accuracy 0.26666666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:26:44,620 | server.py:215 | evaluate_round: strategy sampled 50 clients (out of 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 395] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 929] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 277] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 642] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 848] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 784] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 180] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 507] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 786] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 991] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 129] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 391] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 785] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 387] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 349] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 279] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 533] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 850] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 223] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 819] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 122] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 857] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 306] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 362] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 948] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 890] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 19] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 491] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 102] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 66] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 364] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 377] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 702] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 656] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 198] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 914] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 296] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 978] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 403] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 465] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 657] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 966] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 342] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 963] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 278] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flower 2022-06-23 14:28:23,573 | server.py:227 | evaluate_round received 50 results and 0 failures\n",
            "INFO flower 2022-06-23 14:28:23,575 | server.py:182 | FL finished in 460.41334921699996\n",
            "INFO flower 2022-06-23 14:28:23,591 | app.py:149 | app_fit: losses_distributed [(1, 0.4581334037780763), (2, 0.45518056106567395), (3, 0.44773124217987054)]\n",
            "INFO flower 2022-06-23 14:28:23,592 | app.py:150 | app_fit: metrics_distributed {}\n",
            "INFO flower 2022-06-23 14:28:23,598 | app.py:151 | app_fit: losses_centralized []\n",
            "INFO flower 2022-06-23 14:28:23,600 | app.py:152 | app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 360] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 677] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1262)\u001b[0m [Client 139] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1261)\u001b[0m [Client 964] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.4581334037780763\n",
              "\tround 2: 0.45518056106567395\n",
              "\tround 3: 0.44773124217987054"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}